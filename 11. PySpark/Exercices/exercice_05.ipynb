{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30189e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, DateType\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "sparkContext = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8413fbb3",
   "metadata": {},
   "source": [
    "## Création d'un DataFrame d'étudiants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "382bb023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du schéma\n",
    "schema_etudiants = StructType([\n",
    "    StructField(\"etudiant_id\", IntegerType(), True),\n",
    "    StructField(\"nom\", StringType(), True),\n",
    "    StructField(\"prenom\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"niveau\", StringType(), True),\n",
    "    StructField(\"filiere\", StringType(), True),\n",
    "    StructField(\"ville_origine\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Données d'exemple\n",
    "donnees_etudiants = [\n",
    "    (1001, \"Dupont\", \"Marie\", 20, \"L2\", \"Informatique\", \"Paris\"),\n",
    "    (1002, \"Martin\", \"Pierre\", 22, \"M1\", \"Mathématiques\", \"Lyon\"),\n",
    "    (1003, \"Bernard\", \"Sophie\", 19, \"L1\", \"Physique\", \"Marseille\"),\n",
    "    (1004, \"Dubois\", \"Thomas\", 21, \"L3\", \"Informatique\", \"Toulouse\"),\n",
    "    (1005, \"Moreau\", \"Emma\", 23, \"M2\", \"Mathématiques\", \"Nice\"),\n",
    "    (1006, \"Petit\", \"Lucas\", 20, \"L2\", \"Physique\", \"Bordeaux\"),\n",
    "    (1007, \"Garcia\", \"Léa\", 19, \"L1\", \"Informatique\", \"Strasbourg\"),\n",
    "    (1008, \"Rodriguez\", \"Antoine\", 24, \"M2\", \"Physique\", \"Lille\")\n",
    "]\n",
    "\n",
    "# Création du DataFrame\n",
    "df_etudiants = spark.createDataFrame(donnees_etudiants, schema_etudiants)\n",
    "df_etudiants.createOrReplaceTempView(\"etudiants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7dad5e",
   "metadata": {},
   "source": [
    "## Création du DataFrame de notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea87f7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_notes = StructType([\n",
    "    StructField(\"note_id\", IntegerType(), True),\n",
    "    StructField(\"etudiant_id\", IntegerType(), True),\n",
    "    StructField(\"matiere\", StringType(), True),\n",
    "    StructField(\"type_evaluation\", StringType(), True),\n",
    "    StructField(\"note\", DoubleType(), True),\n",
    "    StructField(\"coefficient\", IntegerType(), True),\n",
    "    StructField(\"semestre\", StringType(), True),\n",
    "    StructField(\"annee\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "donnees_notes = [\n",
    "    (1, 1001, \"Algorithmique\", \"Examen\", 16.5, 3, \"S1\", 2024),\n",
    "    (2, 1001, \"Base de Données\", \"TP\", 14.0, 2, \"S1\", 2024),\n",
    "    (3, 1001, \"Mathématiques\", \"Examen\", 18.5, 4, \"S1\", 2024),\n",
    "    (4, 1002, \"Analyse\", \"Examen\", 17.0, 4, \"S1\", 2024),\n",
    "    (5, 1002, \"Algèbre\", \"Contrôle\", 15.5, 2, \"S1\", 2024),\n",
    "    (6, 1003, \"Physique Quantique\", \"Examen\", 13.0, 4, \"S1\", 2024),\n",
    "    (7, 1003, \"Thermodynamique\", \"TP\", 16.0, 2, \"S1\", 2024),\n",
    "    (8, 1004, \"Programmation\", \"Projet\", 17.5, 3, \"S1\", 2024),\n",
    "    (9, 1004, \"Réseaux\", \"Examen\", 14.5, 3, \"S1\", 2024),\n",
    "    (10, 1005, \"Statistiques\", \"Examen\", 19.0, 4, \"S1\", 2024),\n",
    "    (11, 1005, \"Probabilités\", \"Contrôle\", 16.5, 2, \"S1\", 2024),\n",
    "    (12, 1001, \"Algorithmique\", \"Projet\", 15.0, 2, \"S2\", 2024),\n",
    "    (13, 1002, \"Topologie\", \"Examen\", 18.0, 3, \"S2\", 2024),\n",
    "    (14, 1003, \"Mécanique\", \"TP\", 12.5, 2, \"S2\", 2024)\n",
    "]\n",
    "\n",
    "df_notes = spark.createDataFrame(donnees_notes, schema_notes)\n",
    "df_notes.createOrReplaceTempView(\"notes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fb3f1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------------+----------------+\n",
      "|    nom|prenom|      filiere|moyenne_ponderee|\n",
      "+-------+------+-------------+----------------+\n",
      "| Moreau|  Emma|Mathématiques|           18.17|\n",
      "| Martin|Pierre|Mathématiques|            17.0|\n",
      "| Dupont| Marie| Informatique|            16.5|\n",
      "| Dubois|Thomas| Informatique|            16.0|\n",
      "|Bernard|Sophie|     Physique|           13.63|\n",
      "+-------+------+-------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculez la moyenne pondérée par coefficient pour chaque étudiant\n",
    "# Formule: SUM(note * coefficient) / SUM(coefficient)\n",
    "\n",
    "requete_q1_1 = \"\"\"\n",
    "SELECT \n",
    "    e.nom,\n",
    "    e.prenom,\n",
    "    e.filiere,\n",
    "    ROUND(SUM(n.note * n.coefficient) / SUM(n.coefficient), 2) as moyenne_ponderee\n",
    "FROM notes n\n",
    "JOIN etudiants e ON n.etudiant_id = e.etudiant_id\n",
    "GROUP BY e.etudiant_id, e.nom, e.prenom, e.filiere\n",
    "ORDER BY moyenne_ponderee DESC\n",
    "\"\"\"\n",
    "\n",
    "q1_1 = spark.sql(requete_q1_1)\n",
    "q1_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b744f415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+--------+--------+------------------+----------------+\n",
      "|           matiere|note_moyenne|note_max|note_min|nombre_evaluations|nombre_etudiants|\n",
      "+------------------+------------+--------+--------+------------------+----------------+\n",
      "|      Statistiques|        19.0|    19.0|    19.0|                 1|               1|\n",
      "|     Mathématiques|        18.5|    18.5|    18.5|                 1|               1|\n",
      "|         Topologie|        18.0|    18.0|    18.0|                 1|               1|\n",
      "|     Programmation|        17.5|    17.5|    17.5|                 1|               1|\n",
      "|           Analyse|        17.0|    17.0|    17.0|                 1|               1|\n",
      "|      Probabilités|        16.5|    16.5|    16.5|                 1|               1|\n",
      "|   Thermodynamique|        16.0|    16.0|    16.0|                 1|               1|\n",
      "|     Algorithmique|       15.75|    16.5|    15.0|                 2|               1|\n",
      "|           Algèbre|        15.5|    15.5|    15.5|                 1|               1|\n",
      "|           Réseaux|        14.5|    14.5|    14.5|                 1|               1|\n",
      "|   Base de Données|        14.0|    14.0|    14.0|                 1|               1|\n",
      "|Physique Quantique|        13.0|    13.0|    13.0|                 1|               1|\n",
      "|         Mécanique|        12.5|    12.5|    12.5|                 1|               1|\n",
      "+------------------+------------+--------+--------+------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pour chaque matière, trouvez :\n",
    "# - La note moyenne\n",
    "# - La note la plus haute\n",
    "# - La note la plus basse\n",
    "# - Le nombre d'évaluations\n",
    "\n",
    "requete_q1_2 = \"\"\"\n",
    "SELECT \n",
    "    matiere,\n",
    "    ROUND(AVG(note), 2) as note_moyenne,\n",
    "    MAX(note) as note_max,\n",
    "    MIN(note) as note_min,\n",
    "    COUNT(*) as nombre_evaluations,\n",
    "    COUNT(DISTINCT etudiant_id) as nombre_etudiants\n",
    "FROM notes\n",
    "GROUP BY matiere\n",
    "ORDER BY note_moyenne DESC\n",
    "\"\"\"\n",
    "\n",
    "q1_2 = spark.sql(requete_q1_2)\n",
    "q1_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8372333f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------------+----------+\n",
      "|    nom|prenom|moyenne_generale|   mention|\n",
      "+-------+------+----------------+----------+\n",
      "| Moreau|  Emma|           18.17| Très Bien|\n",
      "| Martin|Pierre|            17.0| Très Bien|\n",
      "| Dupont| Marie|            16.5| Très Bien|\n",
      "| Dubois|Thomas|            16.0|      Bien|\n",
      "|Bernard|Sophie|           13.63|Assez Bien|\n",
      "+-------+------+----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classez les étudiants par leur moyenne générale\n",
    "# Affichez: rang, nom, prénom, moyenne, mention\n",
    "# Mentions: >16 \"Très Bien\", >14 \"Bien\", >12 \"Assez Bien\", >10 \"Passable\", <=10 \"Insuffisant\"\n",
    "\n",
    "# Votre code ici :\n",
    "requete_q1_3 = \"\"\"\n",
    "SELECT \n",
    "    e.nom,\n",
    "    e.prenom,\n",
    "    ROUND(SUM(n.note * n.coefficient) / SUM(n.coefficient), 2) as moyenne_generale,\n",
    "    CASE \n",
    "        WHEN ROUND(SUM(n.note * n.coefficient) / SUM(n.coefficient), 2) > 16 THEN 'Très Bien'\n",
    "        WHEN ROUND(SUM(n.note * n.coefficient) / SUM(n.coefficient), 2) > 14 THEN 'Bien'\n",
    "        WHEN ROUND(SUM(n.note * n.coefficient) / SUM(n.coefficient), 2) > 12 THEN 'Assez Bien'\n",
    "        WHEN ROUND(SUM(n.note * n.coefficient) / SUM(n.coefficient), 2) > 10 THEN 'Passable'\n",
    "        ELSE 'Insuffisant'\n",
    "    END as mention\n",
    "FROM notes n\n",
    "JOIN etudiants e ON n.etudiant_id = e.etudiant_id\n",
    "GROUP BY e.etudiant_id, e.nom, e.prenom\n",
    "ORDER BY moyenne_generale DESC\n",
    "\"\"\"\n",
    "\n",
    "q1_3 = spark.sql(requete_q1_3)\n",
    "q1_3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6276e7f5",
   "metadata": {},
   "source": [
    "## Exercice 2 : Analyse de la fréquentation des cours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0341b2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_presences = StructType([\n",
    "    StructField(\"presence_id\", IntegerType(), True),\n",
    "    StructField(\"etudiant_id\", IntegerType(), True),\n",
    "    StructField(\"cours\", StringType(), True),\n",
    "    StructField(\"date_cours\", StringType(), True),\n",
    "    StructField(\"present\", StringType(), True),\n",
    "    StructField(\"duree_cours\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "schema_cours = StructType([\n",
    "    StructField(\"cours_id\", StringType(), True),\n",
    "    StructField(\"nom_cours\", StringType(), True),\n",
    "    StructField(\"enseignant\", StringType(), True),\n",
    "    StructField(\"salle\", StringType(), True),\n",
    "    StructField(\"capacite_salle\", IntegerType(), True),\n",
    "    StructField(\"filiere\", StringType(), True)\n",
    "])\n",
    "\n",
    "donnees_presences = [\n",
    "    (1, 1001, \"ALGO101\", \"2024-01-15\", \"Oui\", 120),\n",
    "    (2, 1001, \"BDD101\", \"2024-01-15\", \"Retard\", 90),\n",
    "    (3, 1001, \"MATH101\", \"2024-01-16\", \"Oui\", 120),\n",
    "    (4, 1002, \"ANA201\", \"2024-01-15\", \"Oui\", 120),\n",
    "    (5, 1002, \"ALG201\", \"2024-01-16\", \"Non\", 90),\n",
    "    (6, 1003, \"PHY101\", \"2024-01-15\", \"Oui\", 120),\n",
    "    (7, 1004, \"PROG201\", \"2024-01-15\", \"Oui\", 180),\n",
    "    (8, 1004, \"RES201\", \"2024-01-16\", \"Retard\", 90),\n",
    "    (9, 1005, \"STAT301\", \"2024-01-15\", \"Oui\", 120),\n",
    "    (10, 1001, \"ALGO101\", \"2024-01-22\", \"Non\", 120),\n",
    "    (11, 1002, \"ANA201\", \"2024-01-22\", \"Oui\", 120),\n",
    "    (12, 1003, \"PHY101\", \"2024-01-22\", \"Retard\", 120)\n",
    "]\n",
    "\n",
    "donnees_cours = [\n",
    "    (\"ALGO101\", \"Algorithmique Niveau 1\", \"Prof. Dupont\", \"A101\", 50, \"Informatique\"),\n",
    "    (\"BDD101\", \"Base de Données\", \"Prof. Martin\", \"B205\", 30, \"Informatique\"),\n",
    "    (\"MATH101\", \"Mathématiques Générales\", \"Prof. Bernard\", \"C301\", 80, \"Mathématiques\"),\n",
    "    (\"ANA201\", \"Analyse Avancée\", \"Prof. Dubois\", \"C302\", 40, \"Mathématiques\"),\n",
    "    (\"ALG201\", \"Algèbre Linéaire\", \"Prof. Moreau\", \"C303\", 35, \"Mathématiques\"),\n",
    "    (\"PHY101\", \"Physique Générale\", \"Prof. Petit\", \"D101\", 60, \"Physique\"),\n",
    "    (\"PROG201\", \"Programmation Avancée\", \"Prof. Garcia\", \"A102\", 25, \"Informatique\"),\n",
    "    (\"RES201\", \"Réseaux Informatiques\", \"Prof. Lopez\", \"A103\", 30, \"Informatique\"),\n",
    "    (\"STAT301\", \"Statistiques Avancées\", \"Prof. Silva\", \"C304\", 45, \"Mathématiques\")\n",
    "]\n",
    "\n",
    "df_presences = spark.createDataFrame(donnees_presences, schema_presences)\n",
    "df_cours = spark.createDataFrame(donnees_cours, schema_cours)\n",
    "\n",
    "df_presences.createOrReplaceTempView(\"presences\")\n",
    "df_cours.createOrReplaceTempView(\"cours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c508d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------------------+-------------+\n",
      "|    nom|prenom|nombre_cours_suivis|taux_presence|\n",
      "+-------+------+-------------------+-------------+\n",
      "|Bernard|Sophie|                  2|       100.00|\n",
      "| Dubois|Thomas|                  2|       100.00|\n",
      "| Moreau|  Emma|                  1|       100.00|\n",
      "| Dupont| Marie|                  4|        75.00|\n",
      "| Martin|Pierre|                  3|        66.67|\n",
      "+-------+------+-------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculez le taux de présence par étudiant\n",
    "# Présent = \"Oui\" ou \"Retard\", Absent = \"Non\"\n",
    "# Affichez: nom, prénom, taux_presence, nombre_cours_suivis\n",
    "\n",
    "requete_q2_1 = \"\"\"\n",
    "WITH stats_presence AS (\n",
    "    SELECT \n",
    "        p.etudiant_id,\n",
    "        COUNT(*) as total_cours,\n",
    "        SUM(CASE WHEN p.present IN ('Oui', 'Retard') THEN 1 ELSE 0 END) as cours_presents\n",
    "    FROM presences p\n",
    "    GROUP BY p.etudiant_id\n",
    ")\n",
    "SELECT \n",
    "    e.nom,\n",
    "    e.prenom,\n",
    "    sp.total_cours as nombre_cours_suivis,\n",
    "    ROUND((sp.cours_presents * 100.0 / sp.total_cours), 2) as taux_presence\n",
    "FROM stats_presence sp\n",
    "JOIN etudiants e ON sp.etudiant_id = e.etudiant_id\n",
    "ORDER BY taux_presence DESC\n",
    "\"\"\"\n",
    "\n",
    "q2_1 = spark.sql(requete_q2_1)\n",
    "q2_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32e5722e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+-----+--------------+------------------+---------------------+-------------------+\n",
      "|           nom_cours|   enseignant|salle|capacite_salle|etudiants_inscrits|taux_occupation_salle|taux_presence_moyen|\n",
      "+--------------------+-------------+-----+--------------+------------------+---------------------+-------------------+\n",
      "|    Algèbre Linéaire| Prof. Moreau| C303|            35|                 1|                 2.86|               0.00|\n",
      "|Algorithmique Niv...| Prof. Dupont| A101|            50|                 1|                 2.00|              50.00|\n",
      "|     Analyse Avancée| Prof. Dubois| C302|            40|                 1|                 2.50|             100.00|\n",
      "|     Base de Données| Prof. Martin| B205|            30|                 1|                 3.33|             100.00|\n",
      "|Mathématiques Gén...|Prof. Bernard| C301|            80|                 1|                 1.25|             100.00|\n",
      "|   Physique Générale|  Prof. Petit| D101|            60|                 1|                 1.67|             100.00|\n",
      "|Programmation Ava...| Prof. Garcia| A102|            25|                 1|                 4.00|             100.00|\n",
      "|Réseaux Informati...|  Prof. Lopez| A103|            30|                 1|                 3.33|             100.00|\n",
      "|Statistiques Avan...|  Prof. Silva| C304|            45|                 1|                 2.22|             100.00|\n",
      "+--------------------+-------------+-----+--------------+------------------+---------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pour chaque cours, calculez :\n",
    "# - Taux de présence moyen\n",
    "# - Nombre d'étudiants inscrits\n",
    "# - Taux d'occupation de la salle (étudiants/capacité)\n",
    "\n",
    "requete_q2_2 = \"\"\"\n",
    "SELECT \n",
    "    c.nom_cours,\n",
    "    c.enseignant,\n",
    "    c.salle,\n",
    "    c.capacite_salle,\n",
    "    COUNT(DISTINCT p.etudiant_id) as etudiants_inscrits,\n",
    "    ROUND((COUNT(DISTINCT p.etudiant_id) * 100.0 / c.capacite_salle), 2) as taux_occupation_salle,\n",
    "    ROUND((SUM(CASE WHEN p.present IN ('Oui', 'Retard') THEN 1 ELSE 0 END) * 100.0 / COUNT(*)), 2) as taux_presence_moyen\n",
    "FROM presences p\n",
    "JOIN cours c ON p.cours = c.cours_id\n",
    "GROUP BY c.cours_id, c.nom_cours, c.enseignant, c.salle, c.capacite_salle\n",
    "ORDER BY taux_presence_moyen ASC\n",
    "\"\"\"\n",
    "\n",
    "q2_2 = spark.sql(requete_q2_2)\n",
    "q2_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41ddf91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+-------------+----------------+------+\n",
      "|nom|prenom|filiere|taux_presence|moyenne_generale|statut|\n",
      "+---+------+-------+-------------+----------------+------+\n",
      "+---+------+-------+-------------+----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Identifiez les étudiants avec un taux de présence < 75%\n",
    "# ET une moyenne générale < 12\n",
    "\n",
    "requete_q2_3 = \"\"\"\n",
    "WITH stats_presence AS (\n",
    "    SELECT \n",
    "        p.etudiant_id,\n",
    "        COUNT(*) as total_cours,\n",
    "        SUM(CASE WHEN p.present IN ('Oui', 'Retard') THEN 1 ELSE 0 END) as cours_presents\n",
    "    FROM presences p\n",
    "    GROUP BY p.etudiant_id\n",
    "),\n",
    "moyennes_etudiants AS (\n",
    "    SELECT \n",
    "        etudiant_id,\n",
    "        ROUND(SUM(note * coefficient) / SUM(coefficient), 2) as moyenne_generale\n",
    "    FROM notes\n",
    "    GROUP BY etudiant_id\n",
    ")\n",
    "SELECT \n",
    "    e.nom,\n",
    "    e.prenom,\n",
    "    e.filiere,\n",
    "    ROUND((sp.cours_presents * 100.0 / sp.total_cours), 2) as taux_presence,\n",
    "    me.moyenne_generale,\n",
    "    'À RISQUE' as statut\n",
    "FROM stats_presence sp\n",
    "JOIN etudiants e ON sp.etudiant_id = e.etudiant_id\n",
    "JOIN moyennes_etudiants me ON sp.etudiant_id = me.etudiant_id\n",
    "WHERE (sp.cours_presents * 100.0 / sp.total_cours) < 75\n",
    "   AND me.moyenne_generale < 12\n",
    "ORDER BY taux_presence ASC, moyenne_generale ASC\n",
    "\"\"\"\n",
    "\n",
    "q2_3 = spark.sql(requete_q2_3)\n",
    "q2_3.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
