# README.md : Plateforme MLOps pour Scoring de CrÃ©dit

## 1. Description du Projet : Scoring de CrÃ©dit IndustrialisÃ©

Ce projet est un Travail Pratique (TP) fil rouge visant Ã  construire une plateforme **MLOps industrielle et complÃ¨te** pour le dÃ©ploiement et la gestion d'un systÃ¨me de **scoring de crÃ©dit**.

L'entreprise **"PrÃªt Ã  dÃ©penser"** cible des clients avec un historique de crÃ©dit limitÃ©. L'enjeu est de fournir une infrastructure **scalable, automatisÃ©e et traÃ§able** pour minimiser les risques (faux nÃ©gatifs) tout en maximisant les opportunitÃ©s (vrais positifs), en utilisant un modÃ¨le optimisÃ© selon un **coÃ»t mÃ©tier** spÃ©cifique.

Le projet met un accent fort sur le **Data Engineering (60%)** et l'automatisation de l'infrastructure via **Kubernetes** et **Airflow**.

### Objectifs ClÃ©s

* **Pipeline ETL** : Ingestion, agrÃ©gation (100+ features), validation, et stockage optimisÃ© (Parquet) des 2.5 GB de donnÃ©es multi-sources.
* **ModÃ©lisation** : EntraÃ®nement de LightGBM/XGBoost, optimisation du seuil de dÃ©cision basÃ©e sur la fonction de coÃ»t $C = 10 \times \text{FN} + 1 \times \text{FP}$.
* **Industrialisation** : Containerisation (Docker), Orchestration (Docker Compose), DÃ©ploiement Cloud-Native (Kubernetes/Helm, HPA).
* **Automatisation** : CI/CD complÃ¨te (GitHub Actions) et orchestration de workflow (Airflow).
* **ObservabilitÃ©** : Monitoring technique (Prometheus/Grafana) et dÃ©tection de dÃ©rive (Evidently AI).

-----

## 2. Architecture Overview

La plateforme est construite autour du principe du **pipeline end-to-end** et repose sur un ensemble d'outils Open Source orchestrÃ©s par Kubernetes.

| Composant | RÃ´le | Technologie(s) |
| :--- | :--- | :--- |
| **Data Layer** | Ingestion, transformation, stockage des features. | Pandas, Parquet, Great Expectations |
| **ML Tracking** | Versioning des modÃ¨les, tracking des expÃ©riences. | MLflow (Tracking Server & Registry) |
| **API/Serving** | Point d'accÃ¨s pour les prÃ©dictions en temps rÃ©el. | FastAPI, Uvicorn, Pydantic |
| **Orchestration** | Gestion et planification du pipeline ML pÃ©riodique. | Apache Airflow |
| **DevOps/Infra** | Build, test, dÃ©ploiement continu, scalabilitÃ©. | Docker, Kubernetes, Helm, GitHub Actions |
| **Monitoring** | Surveillance de la santÃ© de l'API et de la performance du modÃ¨le (drift). | Prometheus, Grafana, Evidently AI |

Le flux de travail principal est gÃ©rÃ© par Airflow pour le rÃ©-entraÃ®nement pÃ©riodique, et par Kubernetes pour le serving en temps rÃ©el et la scalabilitÃ©.

-----

## 3. Instructions d'Installation et PrÃ©requis

Pour dÃ©ployer la plateforme localement ou sur un cluster Cloud (GKE, par exemple), les outils suivants sont requis.

### PrÃ©requis Logiciels

1. **Git** : SystÃ¨me de contrÃ´le de version.
2. **Python 3.9+** : Environnement d'exÃ©cution principal.
3. **Docker** : Pour la containerisation.
4. **Docker Compose** : Pour l'orchestration locale des services de base (MLflow, PostgreSQL).
5. **Kubernetes CLI (`kubectl`)** : Pour interagir avec le cluster.
6. **Minikube / Kind** : (Optionnel) Pour un cluster K8s local.
7. **Helm 3+** : Pour le packaging et le dÃ©ploiement sur Kubernetes.

### Ã‰tapes de Configuration

#### A. Clonage du RÃ©pertoire

```bash
git clone https://github.com/votre_repo/mlops-credit-scoring-tp.git
cd mlops-credit-scoring-tp
```

#### B. PrÃ©paration des DonnÃ©es

1. TÃ©lÃ©chargez les 8 fichiers CSV du jeu de donnÃ©es "Home Credit Default Risk" (Kaggle).
2. Placez tous les fichiers dans le rÃ©pertoire dÃ©diÃ© :

    ```bash
    mkdir -p infra/data/raw
    # Copiez vos 8 fichiers CSV ici
    ```

#### C. Configuration de l'Environnement Python

```bash
# CrÃ©ez un environnement virtuel (recommandÃ©)
python3 -m venv venv
source venv/bin/activate
# Installez les dÃ©pendances
pip install -r requirements.txt
# Installez les hooks de qualitÃ© (Partie 6)
pip install pre-commit
pre-commit install
```

-----

## 4. Guide de DÃ©marrage Rapide

Ce guide permet de lancer la pile complÃ¨te des services nÃ©cessaires (Postgres, MLflow) et de dÃ©marrer l'API pour un test rapide.

### Ã‰tape 1 : DÃ©marrage des Services de Base (Local)

Utilisez Docker Compose pour lancer la base de donnÃ©es (PostgreSQL) et le serveur de tracking MLflow.

```bash
# 1. Build des images (API et MLflow)
docker-compose build

# 2. Lancement des services (Postgres, MLflow)
docker-compose up -d postgres mlflow-server
```

### Ã‰tape 2 : ExÃ©cution du Pipeline ETL et EntraÃ®nement

ExÃ©cutez le script d'entraÃ®nement pour gÃ©nÃ©rer les features, entraÃ®ner le modÃ¨le, l'Ã©valuer, et l'enregistrer dans le MLflow Registry.

```bash
# 1. ExÃ©cution du pipeline Data + Feature Engineering (Partie 1)
python src/data/ingestion.py
python src/features/engineering.py

# 2. EntraÃ®nement et Enregistrement du ModÃ¨le (Partie 2)
# Cela trackera l'expÃ©rimentation et enregistrera le meilleur modÃ¨le
python src/model/train.py

# VÃ©rifiez le rÃ©sultat sur l'interface MLflow : http://localhost:5000
```

### Ã‰tape 3 : DÃ©marrage de l'API de PrÃ©diction (Local)

Une fois le modÃ¨le enregistrÃ© dans MLflow Registry, dÃ©marrez l'API pour le serving local.

```bash
# Lancer l'API FastAPI avec Uvicorn
uvicorn src.api.main:app --host 0.0.0.0 --port 8000
```

Vous pouvez maintenant tester l'endpoint `/health` : `curl http://localhost:8000/health`

### Ã‰tape 4 : DÃ©ploiement sur Kubernetes (Production)

Pour le dÃ©ploiement complet sur un cluster K8s (Minikube/GKE), utilisez le Helm Chart :

```bash
# 1. CrÃ©er le namespace (si non existant)
kubectl create namespace mlops-credit-scoring

# 2. DÃ©ploiement initial en staging/dev
helm install credit-scoring infra/helm/credit-scoring-chart -f infra/helm/credit-scoring-chart/values-dev.yaml -n mlops-credit-scoring
```

> ğŸ’¡ **Note Importante :** La pipeline CI/CD via GitHub Actions gÃ¨re l'Ã©tape de dÃ©ploiement rÃ©elle et automatisÃ©e (GitOps).
